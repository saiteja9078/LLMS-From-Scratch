{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken torch"
      ],
      "metadata": {
        "id": "H64cJy1ivH-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"rakibulhasanshaon69/the-verdict-txt\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZIg5KSLhm27",
        "outputId": "7cde8043-a27a-4825-d5cb-13d2dbbcf8cd"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.12), please consider upgrading to the latest version (0.3.13).\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/rakibulhasanshaon69/the-verdict-txt?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8.86k/8.86k [00:00<00:00, 3.15MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n",
            "Path to dataset files: /root/.cache/kagglehub/datasets/rakibulhasanshaon69/the-verdict-txt/versions/1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Creating input target pairs"
      ],
      "metadata": {
        "id": "V70C84G2F7j-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/root/.cache/kagglehub/datasets/rakibulhasanshaon69/the-verdict-txt/versions/1/the-verdict.txt\",\"r\",encoding=\"utf-8\") as f:\n",
        "  raw_text = f.read()\n",
        "  f.close()"
      ],
      "metadata": {
        "id": "mtTQ4pMMW3_I"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "tokenizer=tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "encodings = tokenizer.encode(raw_text)\n"
      ],
      "metadata": {
        "id": "RXmszvuLhmFQ"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_enc = encodings[50:]"
      ],
      "metadata": {
        "id": "7sA3KF1uh9ea"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context_len = 4\n",
        "\n",
        "x = sample_enc[:context_len]\n",
        "y = sample_enc[1:context_len+1]"
      ],
      "metadata": {
        "id": "uVChM3XBiR1I"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x,y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41GCLns0n0Iw",
        "outputId": "4c649f84-fc02-4eb0-cc94-86097f759979"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([290, 4920, 2241, 287], [4920, 2241, 287, 257])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(context_len):\n",
        "  input = x[:i+1]\n",
        "  output = y[i]\n",
        "  print(str(input)+\"---->\"+str(output))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5iMFHWDPn0to",
        "outputId": "3f1d008f-7a48-4264-ab0f-f185a0a6415d"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[290]---->4920\n",
            "[290, 4920]---->2241\n",
            "[290, 4920, 2241]---->287\n",
            "[290, 4920, 2241, 287]---->257\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###left of the arrow refers to the token input to the llm , and right of the id is the token llms needs to predict"
      ],
      "metadata": {
        "id": "9-h5oOmgpJxH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(context_len):\n",
        "  input = x[:i+1]\n",
        "  output = y[i:i+1]\n",
        "  print(tokenizer.decode(input)+\"---->\"+tokenizer.decode(output))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hdnDu6choRev",
        "outputId": "5c7df56c-345f-4906-821b-d4dc9669912d"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " and----> established\n",
            " and established----> himself\n",
            " and established himself----> in\n",
            " and established himself in----> a\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "class GPTDatasetV1(Dataset):\n",
        "  def __init__(self,text,tokenizer,context_len,stride):\n",
        "    self.input_ids = []\n",
        "    self.target_ids = []\n",
        "\n",
        "    token_ids = tokenizer.encode(text,allowed_special={\"<|endoftext|>\"})\n",
        "\n",
        "    for i in range(0,len(token_ids)-context_len,stride):\n",
        "      in_chunk = token_ids[i:i+context_len]\n",
        "      out_chunk = token_ids[i+1:i+context_len+1]\n",
        "      self.input_ids.append(torch.tensor(in_chunk))\n",
        "      self.target_ids.append(torch.tensor(out_chunk))\n",
        "  def __len__(self):\n",
        "      return len(self.input_ids)\n",
        "  def __getitem__(self,idx):\n",
        "      return self.input_ids[idx],self.target_ids[idx]"
      ],
      "metadata": {
        "id": "EkzJOJA0oce8"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = GPTDatasetV1(raw_text,tokenizer,4,1)\n",
        "\n",
        "dataloader = DataLoader(dataset,batch_size=1,shuffle=False,drop_last=True,num_workers=0)"
      ],
      "metadata": {
        "id": "Uv0_lLbBvNPZ"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_iter = iter(dataloader)\n",
        "\n",
        "first = next(data_iter)\n",
        "first"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WdpVwu1fxYzi",
        "outputId": "0eaa8f71-8f0a-46f0-bb7e-2a15184b672a"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[  40,  367, 2885, 1464]]), tensor([[ 367, 2885, 1464, 1807]])]"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_j0UX6rLD5l1",
        "outputId": "1272735e-cb17-4a48-ce80-0f1293cefcb9"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "256"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lmbJJYleD_zF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
