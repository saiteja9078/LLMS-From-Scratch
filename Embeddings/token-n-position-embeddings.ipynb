{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken torch"
      ],
      "metadata": {
        "id": "H64cJy1ivH-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"rakibulhasanshaon69/the-verdict-txt\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZIg5KSLhm27",
        "outputId": "f981c8d1-e777-452c-f37c-0e75b6d64554"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.12), please consider upgrading to the latest version (0.3.13).\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/rakibulhasanshaon69/the-verdict-txt?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8.86k/8.86k [00:00<00:00, 23.3MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n",
            "Path to dataset files: /root/.cache/kagglehub/datasets/rakibulhasanshaon69/the-verdict-txt/versions/1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Creating input target pairs"
      ],
      "metadata": {
        "id": "V70C84G2F7j-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/root/.cache/kagglehub/datasets/rakibulhasanshaon69/the-verdict-txt/versions/1/the-verdict.txt\",\"r\",encoding=\"utf-8\") as f:\n",
        "  raw_text = f.read()\n",
        "  f.close()"
      ],
      "metadata": {
        "id": "mtTQ4pMMW3_I"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "tokenizer=tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "encodings = tokenizer.encode(raw_text)\n"
      ],
      "metadata": {
        "id": "RXmszvuLhmFQ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_enc = encodings[50:]"
      ],
      "metadata": {
        "id": "7sA3KF1uh9ea"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context_len = 4\n",
        "\n",
        "x = sample_enc[:context_len]\n",
        "y = sample_enc[1:context_len+1]"
      ],
      "metadata": {
        "id": "uVChM3XBiR1I"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x,y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41GCLns0n0Iw",
        "outputId": "2f97f444-d71e-48f0-8bd3-571aee2accee"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([290, 4920, 2241, 287], [4920, 2241, 287, 257])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(context_len):\n",
        "  input = x[:i+1]\n",
        "  output = y[i]\n",
        "  print(str(input)+\"---->\"+str(output))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5iMFHWDPn0to",
        "outputId": "47512855-972f-4cd5-868b-be1514b200c9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[290]---->4920\n",
            "[290, 4920]---->2241\n",
            "[290, 4920, 2241]---->287\n",
            "[290, 4920, 2241, 287]---->257\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###left of the arrow refers to the token input to the llm , and right of the id is the token llms needs to predict"
      ],
      "metadata": {
        "id": "9-h5oOmgpJxH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(context_len):\n",
        "  input = x[:i+1]\n",
        "  output = y[i:i+1]\n",
        "  print(tokenizer.decode(input)+\"---->\"+tokenizer.decode(output))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hdnDu6choRev",
        "outputId": "ab4d93e7-ba37-4cdd-dd29-734a3e6dee51"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " and----> established\n",
            " and established----> himself\n",
            " and established himself----> in\n",
            " and established himself in----> a\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "class GPTDatasetV1(Dataset):\n",
        "  def __init__(self,text,tokenizer,context_len,stride):\n",
        "    self.input_ids = []\n",
        "    self.target_ids = []\n",
        "\n",
        "    token_ids = tokenizer.encode(text,allowed_special={\"<|endoftext|>\"})\n",
        "\n",
        "    for i in range(0,len(token_ids)-context_len,stride):\n",
        "      in_chunk = token_ids[i:i+context_len]\n",
        "      out_chunk = token_ids[i+1:i+context_len+1]\n",
        "      self.input_ids.append(torch.tensor(in_chunk))\n",
        "      self.target_ids.append(torch.tensor(out_chunk))\n",
        "  def __len__(self):\n",
        "      return len(self.input_ids)\n",
        "  def __getitem__(self,idx):\n",
        "      return self.input_ids[idx],self.target_ids[idx]"
      ],
      "metadata": {
        "id": "EkzJOJA0oce8"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = 4\n",
        "dataset = GPTDatasetV1(raw_text,tokenizer,max_len,max_len)\n",
        "dataloader = DataLoader(dataset,batch_size=8,shuffle=False,drop_last=True) #manages inputing, batching of the data"
      ],
      "metadata": {
        "id": "Uv0_lLbBvNPZ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_iter = iter(dataloader)\n",
        "input_tokens,output_tokens = next(data_iter)"
      ],
      "metadata": {
        "id": "WdpVwu1fxYzi"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 50257\n",
        "embed_dim = 256\n",
        "\n",
        "\n",
        "token_embed_layer = torch.nn.Embedding(vocab_size,embed_dim)"
      ],
      "metadata": {
        "id": "_j0UX6rLD5l1"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = token_embed_layer(input_tokens)\n",
        "embeddings.shape"
      ],
      "metadata": {
        "id": "lmbJJYleD_zF",
        "outputId": "000c4d35-c0e5-4f17-85e8-b96ac87816aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([8, 4, 256])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "position_embed_layer = torch.nn.Embedding(context_len,embed_dim)\n",
        "position_embed_layer(torch.arange(context_len)).shape"
      ],
      "metadata": {
        "id": "vImKidNZ7HUg",
        "outputId": "5670e9a1-f47e-43bf-9a82-911bfa58f077",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 256])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AHoeBS9cEwYt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
